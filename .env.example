# --- LLM Providers (at least one API key required) ---
# OpenAI
OPENAI_API_KEY=  # <-- put your key here
OPENAI_MODEL=gpt-4o-mini

# Gemini
GEMINI_API_KEY=      # <-- put your key here
GEMINI_MODEL=gemini-1.5-flash

# DeepSeek
DEEPSEEK_API_KEY=  # <-- put your key here
DEEPSEEK_MODEL=deepseek-chat
# If you use the official endpoint, you don't need to change this:
DEEPSEEK_BASE_URL=https://api.deepseek.com

# Default provider when the first POST does not include X-LLM-Provider.
# Must be one of: gemini | openai | deepseek
DEFAULT_PROVIDER=gemini

# --- Server ---

# Host port (docker-compose maps "${PORT:-8000}:8000")
PORT=8000
# Uvicorn workers (optional; 1 is fine for local)
WORKERS=1

# --- Persistence ---

# 1 = use SQLite; 0 = in-memory store
USE_DB=1
# Path inside the container (matches docker-compose volume ./data:/app/data)
DATABASE_URL=sqlite:////app/data/conversations.db
